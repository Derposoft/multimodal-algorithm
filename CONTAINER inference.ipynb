{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading pip-20.2.1-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 10.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 20.0.2\n",
      "    Uninstalling pip-20.0.2:\n",
      "      Successfully uninstalled pip-20.0.2\n",
      "Successfully installed pip-20.2.1\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-1.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 17.2 MB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyarrow) (1.18.1)\n",
      "Installing collected packages: pyarrow\n",
      "Successfully installed pyarrow-1.0.0\n",
      "Collecting pandarallel\n",
      "  Downloading pandarallel-1.4.8.tar.gz (14 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.2.zip (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pandarallel, dill\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandarallel: filename=pandarallel-1.4.8-py3-none-any.whl size=16111 sha256=c60030d2525f75a475f479c4f4249eea80ba88bba219655d7a9844107ff2d89a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e9/46/8f/698a358b97ccf5efe84a301297dbf98b19207ff527e0f2512e\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.2-py3-none-any.whl size=78912 sha256=cf8d9528c599346297600ef1c915a12a7663ed4d3e1441fbcdf7a5cf5d50f6fb\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/02/49/cf/660924cd9bc5fcddc3a0246fe39800c83028d3ccea244de352\n",
      "Successfully built pandarallel dill\n",
      "Installing collected packages: dill, pandarallel\n",
      "Successfully installed dill-0.3.2 pandarallel-1.4.8\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.0.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Collecting mxnet\n",
      "  Downloading mxnet-1.6.0-py2.py3-none-any.whl (68.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 68.7 MB 97 kB/s s eta 0:00:01     |█████████████▏                  | 28.3 MB 14.7 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
      "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.23.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (1.18.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.8)\n",
      "Installing collected packages: graphviz, mxnet\n",
      "Successfully installed graphviz-0.8.4 mxnet-1.6.0\n",
      "Collecting autogluon\n",
      "  Downloading autogluon-0.0.12-py3-none-any.whl (515 kB)\n",
      "\u001b[K     |████████████████████████████████| 515 kB 9.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.38.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (4.44.1)\n",
      "Collecting catboost<0.24\n",
      "  Downloading catboost-0.23.2-cp36-none-manylinux1_x86_64.whl (64.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 64.8 MB 63 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-optimize\n",
      "  Downloading scikit_optimize-0.7.4-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 15.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (0.8.4)\n",
      "Requirement already satisfied: pytest in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (5.4.1)\n",
      "Requirement already satisfied: tornado>=5.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (6.0.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.23.0)\n",
      "Requirement already satisfied: cryptography>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.8)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (5.7.0)\n",
      "Requirement already satisfied: distributed>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.14.0)\n",
      "Collecting openml\n",
      "  Downloading openml-0.10.2.tar.gz (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 78.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gluoncv<1.0,>=0.5.0\n",
      "  Downloading gluoncv-0.7.0-py2.py3-none-any.whl (752 kB)\n",
      "\u001b[K     |████████████████████████████████| 752 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (1.18.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (1.14.27)\n",
      "Collecting pandas<1.0,>=0.24.0\n",
      "  Downloading pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.4 MB 60.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (1.4.1)\n",
      "Requirement already satisfied: networkx<3.0,>=2.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.4)\n",
      "Requirement already satisfied: dask>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.14.0)\n",
      "Collecting lightgbm<3.0,>=2.3.0\n",
      "  Downloading lightgbm-2.3.1-py2.py3-none-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 48.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: paramiko>=2.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (2.7.1)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (3.1.3)\n",
      "Collecting Pillow<=6.2.1\n",
      "  Downloading Pillow-6.2.1-cp36-cp36m-manylinux1_x86_64.whl (2.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.1 MB 58.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cython in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (0.29.15)\n",
      "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from autogluon) (0.22.1)\n",
      "Collecting ConfigSpace<=0.4.10\n",
      "  Downloading ConfigSpace-0.4.10.tar.gz (882 kB)\n",
      "\u001b[K     |████████████████████████████████| 882 kB 57.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from catboost<0.24->autogluon) (1.14.0)\n",
      "Requirement already satisfied: plotly in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from catboost<0.24->autogluon) (4.8.1)\n",
      "Collecting pyaml>=16.9\n",
      "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from scikit-optimize->autogluon) (0.14.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (1.8.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (20.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (0.1.9)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pytest->autogluon) (1.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->autogluon) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->autogluon) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->autogluon) (2020.4.5.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->autogluon) (3.0.4)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cryptography>=2.8->autogluon) (1.14.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (0.10.0)\n",
      "Requirement already satisfied: cloudpickle>=0.2.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (1.3.0)\n",
      "Requirement already satisfied: click>=6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (7.1.1)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (1.6.0)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (46.1.3.post20200330)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (2.1.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (2.0.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (1.0.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from distributed>=2.6.0->autogluon) (5.3.1)\n",
      "Collecting liac-arff>=2.4.0\n",
      "  Downloading liac-arff-2.4.0.tar.gz (15 kB)\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.12.0-py2.py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from openml->autogluon) (2.8.1)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->autogluon) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->autogluon) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->autogluon) (1.17.27)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas<1.0,>=0.24.0->autogluon) (2019.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from networkx<3.0,>=2.3->autogluon) (4.4.2)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paramiko>=2.4->autogluon) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from paramiko>=2.4->autogluon) (3.1.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->autogluon) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->autogluon) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from matplotlib->autogluon) (2.4.6)\n",
      "Collecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from plotly->catboost<0.24->autogluon) (1.3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=0.12->pytest->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pycparser in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->autogluon) (2.20)\n",
      "Requirement already satisfied: heapdict in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=2.6.0->autogluon) (1.0.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.27->boto3->autogluon) (0.15.2)\n",
      "Building wheels for collected packages: openml, ConfigSpace, liac-arff, typing\n",
      "  Building wheel for openml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openml: filename=openml-0.10.2-py3-none-any.whl size=190318 sha256=64f744f14f1540b694f50b2db0c2f15c7cf8f57ad23546a6219d82654f644781\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/45/83/27/a45cc845ff2497e34bfc17403e649249e5e717adb08698903d\n",
      "  Building wheel for ConfigSpace (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.10-cp36-cp36m-linux_x86_64.whl size=3001041 sha256=c87fc655bce1c7787650695258f33ecf69a0373bd5ba093f2c1bf3011fc609ef\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/70/71/a2/00ca7cb0f71294d73e8791d6fe5cd0c7401066ec3b7e1026db\n",
      "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for liac-arff: filename=liac_arff-2.4.0-py3-none-any.whl size=13333 sha256=0f7c598957208d72e1338d39b5edd86c3243d51153ccdfa59b91b89eed9f28b9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ba/2a/e1/6f7be2e2ea150e2486bff64fd6f0670f4f35f4c8f31c819fb8\n",
      "  Building wheel for typing (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26308 sha256=fd201ea2c2a39716e82ece868f21af17d107c6f71a6261a8b1289443c995ccd2\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5f/63/c2/b85489bbea28cb5d36cfe197244f898428004fa3caa7a23116\n",
      "Successfully built openml ConfigSpace liac-arff typing\n",
      "Installing collected packages: pandas, catboost, pyaml, scikit-optimize, liac-arff, xmltodict, openml, Pillow, portalocker, gluoncv, lightgbm, typing, ConfigSpace, autogluon\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.0.3\n",
      "    Uninstalling pandas-1.0.3:\n",
      "      Successfully uninstalled pandas-1.0.3\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 7.0.0\n",
      "    Uninstalling Pillow-7.0.0:\n",
      "      Successfully uninstalled Pillow-7.0.0\n",
      "Successfully installed ConfigSpace-0.4.10 Pillow-6.2.1 autogluon-0.0.12 catboost-0.23.2 gluoncv-0.7.0 liac-arff-2.4.0 lightgbm-2.3.1 openml-0.10.2 pandas-0.25.3 portalocker-2.0.0 pyaml-20.4.0 scikit-optimize-0.7.4 typing-3.7.4.3 xmltodict-0.12.0\n",
      "INFO: Pandarallel will run on 32 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install pyarrow\n",
    "!pip install pandarallel\n",
    "!pip install pandas\n",
    "!pip install mxnet\n",
    "!pip install autogluon\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import sagemaker\n",
    "import boto3\n",
    "import os, time\n",
    "import autogluon as ag\n",
    "import mxnet as mx\n",
    "from mxnet import nd, gluon, init, autograd\n",
    "from mxnet.gluon import nn\n",
    "import pickle\n",
    "\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = str(os.cpu_count())\n",
    "pandarallel.initialize()\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "mx.random.seed(127)\n",
    "contexts = [mx.cpu()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_path = 's3://amlc-data/multimodal-alg-test/test.csv'\n",
    "model_path = './opt/ml/model-big/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,9,10,11,12,13,14,15,16,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# text/numeric data\n",
    "#dataset = pd.read_csv(train_dataset_path)\n",
    "test_dataset = pd.read_csv(test_dataset_path, header=None)\n",
    "print('data read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img_image', 'label', 'marketplace_id_num', 'item_name_text', 'product_description_text', 'bullet_point_text', 'brand_text', 'manufacturer_text', 'generic_keyword_text', 'material_text', 'number_of_items_num', 'case_pack_quantity_num', 'item_package_quantity_num', 'item_dimensions_height_num', 'item_dimensions_width_num', 'item_dimensions_length_num', 'normalized_item_weight_num', 'normalized_item_package_weight_num', 'list_price_currency_cat', 'list_price_value_num', 'list_price_value_with_tax_num', 'ID']\n",
      "['img_image', 'marketplace_id_num', 'item_name_text', 'product_description_text', 'bullet_point_text', 'brand_text', 'manufacturer_text', 'generic_keyword_text', 'material_text', 'number_of_items_num', 'case_pack_quantity_num', 'item_package_quantity_num', 'item_dimensions_height_num', 'item_dimensions_width_num', 'item_dimensions_length_num', 'normalized_item_weight_num', 'normalized_item_package_weight_num', 'list_price_currency_cat', 'list_price_value_num', 'list_price_value_with_tax_num', 'ID']\n"
     ]
    }
   ],
   "source": [
    "model_config = {}\n",
    "\n",
    "with open(model_path+'model_config.pkl', 'rb') as f:\n",
    "    model_config = pickle.load(f)\n",
    "columns = model_config['columns']\n",
    "columns_text = model_config['columns_text']\n",
    "columns_num = model_config['columns_num']\n",
    "columns_cat = model_config['columns_cat']\n",
    "columns_img = model_config['columns_img']\n",
    "has_text = model_config['has_text']\n",
    "has_num = model_config['has_num']\n",
    "has_cat = model_config['has_cat']\n",
    "has_img = model_config['has_img']\n",
    "catmap = model_config['catmap']\n",
    "invcatmap = model_config['invcatmap']\n",
    "numcats = model_config['numcats']\n",
    "cats = model_config['cats']\n",
    "target_column = 'label'\n",
    "\n",
    "#columns = columns[1:]\n",
    "print(columns)\n",
    "columns.remove('label')\n",
    "print(columns)\n",
    "test_dataset.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_image</th>\n",
       "      <th>marketplace_id_num</th>\n",
       "      <th>item_name_text</th>\n",
       "      <th>product_description_text</th>\n",
       "      <th>bullet_point_text</th>\n",
       "      <th>brand_text</th>\n",
       "      <th>manufacturer_text</th>\n",
       "      <th>generic_keyword_text</th>\n",
       "      <th>material_text</th>\n",
       "      <th>number_of_items_num</th>\n",
       "      <th>...</th>\n",
       "      <th>item_package_quantity_num</th>\n",
       "      <th>item_dimensions_height_num</th>\n",
       "      <th>item_dimensions_width_num</th>\n",
       "      <th>item_dimensions_length_num</th>\n",
       "      <th>normalized_item_weight_num</th>\n",
       "      <th>normalized_item_package_weight_num</th>\n",
       "      <th>list_price_currency_cat</th>\n",
       "      <th>list_price_value_num</th>\n",
       "      <th>list_price_value_with_tax_num</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAsICAgICAsICA...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Greenworks 40V 300W Cordless Power Inverter IV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ideal for camping, tailgating, disaster prepar...</td>\n",
       "      <td>Greenworks</td>\n",
       "      <td>GreenWorks</td>\n",
       "      <td>40V Power Inverter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2.76</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.30513659104</td>\n",
       "      <td>USD</td>\n",
       "      <td>39.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9e4f7cbe4cf54efeb9a7669ec6775cfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bankers Box SmoothMove Wardrobe Moving Boxes, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Designed specifically to move and store hangin...</td>\n",
       "      <td>Bankers Box</td>\n",
       "      <td>Fellowes</td>\n",
       "      <td>Box Mailers</td>\n",
       "      <td>Cardboard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.25</td>\n",
       "      <td>20.38</td>\n",
       "      <td>20.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.6008083286</td>\n",
       "      <td>USD</td>\n",
       "      <td>57.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5d76c57ac2b94d4ebe0cbd21b7fc5d68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>High Sierra Powerglide Lightweight Wheeled Lap...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LARGE, MULTI-COMPARTMENT DESIGN: this student ...</td>\n",
       "      <td>High Sierra</td>\n",
       "      <td>High Sierra Sport Company</td>\n",
       "      <td>backpack</td>\n",
       "      <td>600D Polyester Waffle Weave</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.60064012428</td>\n",
       "      <td>USD</td>\n",
       "      <td>79.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94eef78c1be74373a63cc11fa0d34c58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Dynamite Screwdriver: #00 Phillips, DYN2826</td>\n",
       "      <td>Dynamite Screwdriver: #00 Phillips, DYN2826</td>\n",
       "      <td>The package height is 0.779\"</td>\n",
       "      <td>Dynamite</td>\n",
       "      <td>Dynamite</td>\n",
       "      <td>Other Accessories</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050706320260000014</td>\n",
       "      <td>USD</td>\n",
       "      <td>11.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dadffba3fbf64885ab723e052fce646c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Elite Screens Yard Master, 100 inch Outdoor Pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-inch Diagonal, 16:9 Aspect Ratio. View Siz...</td>\n",
       "      <td>Elite Screens</td>\n",
       "      <td>Elite Screens Inc.</td>\n",
       "      <td>DaLite Projector Screen Theater White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>99.6</td>\n",
       "      <td>32.2</td>\n",
       "      <td>37.05088775172</td>\n",
       "      <td>USD</td>\n",
       "      <td>263.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f3bd48869f484f70a573908b69b10d81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73056</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Disney Cars 2 Spies Pull 'n' Race Die Cast Set</td>\n",
       "      <td>A notorious spy ring has been rounded up in th...</td>\n",
       "      <td>Genuine, Original, Authentic Disney Store</td>\n",
       "      <td>Disney Pixar</td>\n",
       "      <td>Disney</td>\n",
       "      <td>diecast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.976648</td>\n",
       "      <td>USD</td>\n",
       "      <td>39.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68d472e6ad8946c9a9d42be832acb4b4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73057</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Delixike Magnifying Glass with Light and Stand...</td>\n",
       "      <td>&lt;p&gt;Calligraphers,clockmakers, jewelers, and mo...</td>\n",
       "      <td>ULTRA BRIGHT MAGNIFYING LAMP FOR READING, WORK...</td>\n",
       "      <td>Delixike</td>\n",
       "      <td>shen zhen de li xi ke ke ji you xian gong si</td>\n",
       "      <td>desktop handsfree table top standing lighted h...</td>\n",
       "      <td>Metal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.75267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9bdcd9a3f1284bbaabe2acb15227514c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73058</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Women's Footed Tights 3 PK Opaque 120D Solid C...</td>\n",
       "      <td>Women's durable footed tights are the ideal co...</td>\n",
       "      <td>3 Pairs of High Quality Microfiber, Medium Thi...</td>\n",
       "      <td>FOMANN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>women' tights soft solid pantyhose   tights fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b035fbeaa74345ebb6681e08c555559f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73059</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Cuckoo Electric Induction Heating Pressure Ric...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Essential: For perfectly cooked rice, bread, s...</td>\n",
       "      <td>Cuckoo</td>\n",
       "      <td>Cuckoo</td>\n",
       "      <td>Cuckoo Electronics 10 Cup Stainless IH Pressur...</td>\n",
       "      <td>Stainless Steel</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>11.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>17.4</td>\n",
       "      <td>18.1</td>\n",
       "      <td>USD</td>\n",
       "      <td>519.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7dc2e157c48e43d18956f59e7a1f9b5f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73060</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Sterilite 19889804 70 Quart/66 Liter Ultra Box...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Outside Dimensions: 26.13 x 16.25 x 13.5</td>\n",
       "      <td>STERILITE</td>\n",
       "      <td>Sterilite</td>\n",
       "      <td>sterilite large storage containers</td>\n",
       "      <td>Plastic</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>14.375</td>\n",
       "      <td>26.25</td>\n",
       "      <td>16.25</td>\n",
       "      <td>5.25</td>\n",
       "      <td>33.001</td>\n",
       "      <td>USD</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b5ee4fe3aeca468999f80a30a7d81e80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73060 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_image marketplace_id_num  \\\n",
       "1      /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAsICAgICAsICA...                1.0   \n",
       "2                                                    NaN                1.0   \n",
       "3                                                    NaN                1.0   \n",
       "4                                                    NaN                1.0   \n",
       "5                                                    NaN                1.0   \n",
       "...                                                  ...                ...   \n",
       "73056                                                NaN                  1   \n",
       "73057                                                NaN                  1   \n",
       "73058                                                NaN                  1   \n",
       "73059                                                NaN                  1   \n",
       "73060                                                NaN                  1   \n",
       "\n",
       "                                          item_name_text  \\\n",
       "1      Greenworks 40V 300W Cordless Power Inverter IV...   \n",
       "2      Bankers Box SmoothMove Wardrobe Moving Boxes, ...   \n",
       "3      High Sierra Powerglide Lightweight Wheeled Lap...   \n",
       "4            Dynamite Screwdriver: #00 Phillips, DYN2826   \n",
       "5      Elite Screens Yard Master, 100 inch Outdoor Pr...   \n",
       "...                                                  ...   \n",
       "73056     Disney Cars 2 Spies Pull 'n' Race Die Cast Set   \n",
       "73057  Delixike Magnifying Glass with Light and Stand...   \n",
       "73058  Women's Footed Tights 3 PK Opaque 120D Solid C...   \n",
       "73059  Cuckoo Electric Induction Heating Pressure Ric...   \n",
       "73060  Sterilite 19889804 70 Quart/66 Liter Ultra Box...   \n",
       "\n",
       "                                product_description_text  \\\n",
       "1                                                    NaN   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4            Dynamite Screwdriver: #00 Phillips, DYN2826   \n",
       "5                                                    NaN   \n",
       "...                                                  ...   \n",
       "73056  A notorious spy ring has been rounded up in th...   \n",
       "73057  <p>Calligraphers,clockmakers, jewelers, and mo...   \n",
       "73058  Women's durable footed tights are the ideal co...   \n",
       "73059                                                NaN   \n",
       "73060                                                NaN   \n",
       "\n",
       "                                       bullet_point_text     brand_text  \\\n",
       "1      Ideal for camping, tailgating, disaster prepar...     Greenworks   \n",
       "2      Designed specifically to move and store hangin...    Bankers Box   \n",
       "3      LARGE, MULTI-COMPARTMENT DESIGN: this student ...    High Sierra   \n",
       "4                           The package height is 0.779\"       Dynamite   \n",
       "5      100-inch Diagonal, 16:9 Aspect Ratio. View Siz...  Elite Screens   \n",
       "...                                                  ...            ...   \n",
       "73056          Genuine, Original, Authentic Disney Store   Disney Pixar   \n",
       "73057  ULTRA BRIGHT MAGNIFYING LAMP FOR READING, WORK...       Delixike   \n",
       "73058  3 Pairs of High Quality Microfiber, Medium Thi...         FOMANN   \n",
       "73059  Essential: For perfectly cooked rice, bread, s...         Cuckoo   \n",
       "73060           Outside Dimensions: 26.13 x 16.25 x 13.5      STERILITE   \n",
       "\n",
       "                                  manufacturer_text  \\\n",
       "1                                        GreenWorks   \n",
       "2                                          Fellowes   \n",
       "3                         High Sierra Sport Company   \n",
       "4                                          Dynamite   \n",
       "5                                Elite Screens Inc.   \n",
       "...                                             ...   \n",
       "73056                                        Disney   \n",
       "73057  shen zhen de li xi ke ke ji you xian gong si   \n",
       "73058                                           NaN   \n",
       "73059                                        Cuckoo   \n",
       "73060                                     Sterilite   \n",
       "\n",
       "                                    generic_keyword_text  \\\n",
       "1                                     40V Power Inverter   \n",
       "2                                            Box Mailers   \n",
       "3                                               backpack   \n",
       "4                                      Other Accessories   \n",
       "5                  DaLite Projector Screen Theater White   \n",
       "...                                                  ...   \n",
       "73056                                            diecast   \n",
       "73057  desktop handsfree table top standing lighted h...   \n",
       "73058  women' tights soft solid pantyhose   tights fo...   \n",
       "73059  Cuckoo Electronics 10 Cup Stainless IH Pressur...   \n",
       "73060                 sterilite large storage containers   \n",
       "\n",
       "                     material_text number_of_items_num  ...  \\\n",
       "1                              NaN                 NaN  ...   \n",
       "2                        Cardboard                 1.0  ...   \n",
       "3      600D Polyester Waffle Weave                 1.0  ...   \n",
       "4                              NaN                 1.0  ...   \n",
       "5                              NaN                 1.0  ...   \n",
       "...                            ...                 ...  ...   \n",
       "73056                          NaN                 NaN  ...   \n",
       "73057                        Metal                 NaN  ...   \n",
       "73058                          NaN                 NaN  ...   \n",
       "73059              Stainless Steel                  10  ...   \n",
       "73060                      Plastic                   4  ...   \n",
       "\n",
       "      item_package_quantity_num item_dimensions_height_num  \\\n",
       "1                           1.0                        0.9   \n",
       "2                           1.0                      34.25   \n",
       "3                           1.0                       14.0   \n",
       "4                           1.0                       0.78   \n",
       "5                           1.0                       83.9   \n",
       "...                         ...                        ...   \n",
       "73056                       NaN                        NaN   \n",
       "73057                         1                        NaN   \n",
       "73058                       NaN                        NaN   \n",
       "73059                         1                       11.4   \n",
       "73060                         4                     14.375   \n",
       "\n",
       "      item_dimensions_width_num item_dimensions_length_num  \\\n",
       "1                          3.82                       2.76   \n",
       "2                         20.38                      20.38   \n",
       "3                           9.0                       21.0   \n",
       "4                           8.0                        3.6   \n",
       "5                           1.3                       99.6   \n",
       "...                         ...                        ...   \n",
       "73056                       NaN                        NaN   \n",
       "73057                       NaN                        NaN   \n",
       "73058                       NaN                        NaN   \n",
       "73059                      16.2                       11.9   \n",
       "73060                     26.25                      16.25   \n",
       "\n",
       "      normalized_item_weight_num normalized_item_package_weight_num  \\\n",
       "1                           1.02                      1.30513659104   \n",
       "2                            NaN                      16.6008083286   \n",
       "3                            6.0                      6.60064012428   \n",
       "4                           0.05               0.050706320260000014   \n",
       "5                           32.2                     37.05088775172   \n",
       "...                          ...                                ...   \n",
       "73056                        NaN                           0.976648   \n",
       "73057                        NaN                            1.75267   \n",
       "73058                        NaN                             0.3125   \n",
       "73059                       17.4                               18.1   \n",
       "73060                       5.25                             33.001   \n",
       "\n",
       "      list_price_currency_cat list_price_value_num  \\\n",
       "1                         USD                39.99   \n",
       "2                         USD                57.52   \n",
       "3                         USD                79.99   \n",
       "4                         USD                 11.2   \n",
       "5                         USD                263.0   \n",
       "...                       ...                  ...   \n",
       "73056                     USD                39.95   \n",
       "73057                     NaN                  NaN   \n",
       "73058                     NaN                  NaN   \n",
       "73059                     USD               519.99   \n",
       "73060                     USD                  112   \n",
       "\n",
       "      list_price_value_with_tax_num                                ID  \n",
       "1                               NaN  9e4f7cbe4cf54efeb9a7669ec6775cfc  \n",
       "2                               NaN  5d76c57ac2b94d4ebe0cbd21b7fc5d68  \n",
       "3                               NaN  94eef78c1be74373a63cc11fa0d34c58  \n",
       "4                               NaN  dadffba3fbf64885ab723e052fce646c  \n",
       "5                               NaN  f3bd48869f484f70a573908b69b10d81  \n",
       "...                             ...                               ...  \n",
       "73056                           NaN  68d472e6ad8946c9a9d42be832acb4b4  \n",
       "73057                           NaN  9bdcd9a3f1284bbaabe2acb15227514c  \n",
       "73058                           NaN  b035fbeaa74345ebb6681e08c555559f  \n",
       "73059                           NaN  7dc2e157c48e43d18956f59e7a1f9b5f  \n",
       "73060                           NaN  b5ee4fe3aeca468999f80a30a7d81e80  \n",
       "\n",
       "[73060 rows x 21 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns checked\n",
      "columns double checked\n"
     ]
    }
   ],
   "source": [
    "# check for same columns\n",
    "for i in range(1, len(columns)):\n",
    "    if not columns[i] in test_dataset.columns and columns[i] != 'label':\n",
    "        print('big fail!', columns[i])\n",
    "        exit(0)\n",
    "print('columns checked')\n",
    "for i in range(1, len(test_dataset.columns)):\n",
    "    if not test_dataset.columns[i] in columns and test_dataset.columns[i] != 'label':\n",
    "        print('big fail!', test_dataset.columns[i])\n",
    "        exit(0)\n",
    "print('columns double checked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, base64\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from io import StringIO, BytesIO\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "def clean_text(data, labelled=False):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # scrub possible html\n",
    "    # stackoverflow.com/questions/753052/strip-html-from-strings-in-python\n",
    "    def strip_tags(html):\n",
    "        s = MLStripper()\n",
    "        s.feed(html)\n",
    "        return s.get_data()\n",
    "    # lowercases and removes special characters\n",
    "    def clean_val(val):\n",
    "        text = val\n",
    "        text = strip_tags(text)\n",
    "        if type(val) == str:\n",
    "            text = text.lower().strip()\n",
    "            text = re.compile(r'[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            words = [w for w in text.split(\" \") if not w in stop_words]\n",
    "            text = \" \".join([lemmatizer.lemmatize(w) for w in words])\n",
    "        return text\n",
    "    # get text cols\n",
    "    text_cols = [x for x in data.columns if x.endswith('_text')]\n",
    "    if len(text_cols) == 0:\n",
    "        print('no text columns found.')\n",
    "        return pd.DataFrame(), None\n",
    "    print('text columns found:', text_cols)\n",
    "    text_data = data[text_cols].copy()\n",
    "    # lazy impute text\n",
    "    text_data = text_data.fillna('')\n",
    "    # clean text cols\n",
    "    for col in text_cols:\n",
    "        print('text cleaning:', col)\n",
    "        text_data[col] = text_data[col].parallel_apply(clean_val)\n",
    "    text_label = None\n",
    "    if labelled:\n",
    "        print('working on labels...')\n",
    "        text_label = mappedlabels.copy()\n",
    "        map2bad = text_data[text_cols[0]] == ''\n",
    "        for col in text_cols[1:]:\n",
    "            map2bad = np.logical_and(map2bad, text_data[col] == '')\n",
    "        text_label[map2bad] = numcats\n",
    "    print(\"done transforming text data.\")\n",
    "    return text_data, text_label\n",
    "def clean_num(data, labelled=False):\n",
    "    # get num cols\n",
    "    num_cols = [x for x in data.columns if x.endswith('_num')]\n",
    "    if len(num_cols) == 0:\n",
    "        print('no numeric columns found.')\n",
    "        return pd.DataFrame(), None\n",
    "    print('numeric columns found:', num_cols)\n",
    "    num_data = data[num_cols].copy()\n",
    "    # impute numeric data\n",
    "    num_data = num_data.fillna(0)\n",
    "    num_label = None\n",
    "    if labelled:\n",
    "        print('working on labels...')\n",
    "        num_label = mappedlabels.copy()\n",
    "    print(\"done transforming numeric data.\")\n",
    "    return num_data, num_label\n",
    "def clean_cat(data, labelled=False):\n",
    "    # get cat cols\n",
    "    cat_cols = [x for x in data.columns if x.endswith('_cat')]\n",
    "    if len(cat_cols) == 0:\n",
    "        print('no categorical columns found.')\n",
    "        return pd.DataFrame(), None\n",
    "    print('categorical columns found:', cat_cols)\n",
    "    cat_data = data[cat_cols].copy()\n",
    "    # impute categorical data\n",
    "    cat_data = cat_data.fillna('unknown')\n",
    "    cat_data_out = pd.get_dummies(cat_data)\n",
    "    cat_label = None\n",
    "    if labelled:\n",
    "        print('working on labels...')\n",
    "        cat_label = mappedlabels.copy()\n",
    "    print(\"done transforming categorical data.\")\n",
    "    return cat_data_out, cat_label\n",
    "def clean_image(data, labelled=False):\n",
    "    import cv2\n",
    "    # normalize image\n",
    "    def normalizeimg(img):\n",
    "        img = img.transpose((2, 0, 1)).expand_dims(axis=0)\n",
    "        rgb_mean = nd.array([0.485, 0.456, 0.406]).reshape((1,3,1,1))\n",
    "        rgb_std = nd.array([0.229, 0.224, 0.225]).reshape((1,3,1,1))\n",
    "        return (img.astype('float32') / 255 - rgb_mean) / rgb_std\n",
    "    def cleanimg(img_bytes):\n",
    "        if img_bytes == '':\n",
    "            return normalizeimg(mx.nd.array([[[0]*3]*224]*244))\n",
    "        img = mx.image.imdecode(base64.b64decode(img_bytes))\n",
    "        img = mx.image.resize_short(img, 256)\n",
    "        img, _ = mx.image.center_crop(img, (224, 224))\n",
    "        return normalizeimg(img)\n",
    "    # get pretrained resnet50\n",
    "    def getresnet():\n",
    "        net = gluon.model_zoo.vision.resnet50_v1(pretrained=True, ctx=contexts)\n",
    "        print('image pre-model created...')\n",
    "        return net\n",
    "    # get cat cols\n",
    "    img_cols = [x for x in data.columns if x.endswith('_image')]\n",
    "    if len(img_cols) == 0:\n",
    "        print('no image columns found.')\n",
    "        return pd.DataFrame(), None\n",
    "    print('image columns found:', img_cols)\n",
    "    img_data = data[img_cols].copy()\n",
    "    # impute categorical data\n",
    "    img_data = img_data.fillna('')\n",
    "    # initialize model to transform images to resnet outputs\n",
    "    img_model = getresnet()\n",
    "    # create suggested img labels\n",
    "    images_out = []\n",
    "    map2bads =  []\n",
    "    for col in img_cols:\n",
    "        map2bads.append(img_data[col] == '')\n",
    "        #temp_col = pd.DataFrame(img_data[col].parallel_apply(cleanimg))\n",
    "        #print(temp_col.head())\n",
    "        #print(temp_col.iloc[0, :])\n",
    "        #print(type(temp_col.iloc[0, :]))\n",
    "        #print(nd.array(temp_col.iloc[0, :].values))\n",
    "        #temp_col = temp_col.parallel_apply(nd.array)\n",
    "        #images_out.append(temp_col.parallel_apply(img_model))\n",
    "        img_data[col] = img_data[col].parallel_apply(cleanimg).parallel_apply(img_model)\n",
    "    image_label = []\n",
    "    if labelled:\n",
    "        print('working on labels...')\n",
    "        import functools\n",
    "        mlabs = mappedlabels.copy()\n",
    "        for i in range(len(map2bads)):\n",
    "            image_label.append(mlabs.copy())\n",
    "            image_label[i][map2bads[i]] = numcats\n",
    "    print(\"done transforming image data.\")\n",
    "    #return images_out, image_label\n",
    "    return img_data, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text columns found: ['item_name_text', 'product_description_text', 'bullet_point_text', 'brand_text', 'manufacturer_text', 'generic_keyword_text', 'material_text']\n",
      "text cleaning: item_name_text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text cleaning: product_description_text\n",
      "text cleaning: bullet_point_text\n",
      "text cleaning: brand_text\n",
      "text cleaning: manufacturer_text\n",
      "text cleaning: generic_keyword_text\n",
      "text cleaning: material_text\n",
      "done transforming text data.\n",
      "numeric columns found: ['marketplace_id_num', 'number_of_items_num', 'case_pack_quantity_num', 'item_package_quantity_num', 'item_dimensions_height_num', 'item_dimensions_width_num', 'item_dimensions_length_num', 'normalized_item_weight_num', 'normalized_item_package_weight_num', 'list_price_value_num', 'list_price_value_with_tax_num']\n",
      "done transforming numeric data.\n",
      "categorical columns found: ['list_price_currency_cat']\n",
      "done transforming categorical data.\n",
      "image columns found: ['img_image']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model file not found. Downloading to /home/ec2-user/.mxnet/models/resnet50_v1-0aee57f9.params.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /home/ec2-user/.mxnet/models/resnet50_v1-0aee57f9.zipffd6db80-53de-4848-95e7-93777a3338b6 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet50_v1-0aee57f9.zip...\n",
      "image pre-model created...\n"
     ]
    }
   ],
   "source": [
    "text_data, _ = clean_text(test_dataset)\n",
    "num_data, _ = clean_num(test_dataset)\n",
    "cat_data, _ = clean_cat(test_dataset)\n",
    "img_data, _ = clean_image(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phase one - per-modality training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading text data\n",
      "loading num data\n",
      "loading cat data\n",
      "loading img data\n"
     ]
    }
   ],
   "source": [
    "from autogluon import TabularPrediction as task\n",
    "\n",
    "if has_text:\n",
    "    print('loading text data')\n",
    "    agluon_text_train_data = task.Dataset(text_data)\n",
    "if has_num:\n",
    "    print('loading num data')\n",
    "    agluon_num_train_data = task.Dataset(num_data)\n",
    "if has_cat:\n",
    "    print('loading cat data')\n",
    "    agluon_cat_train_data = task.Dataset(cat_data)\n",
    "if has_img:\n",
    "    print('loading img data')\n",
    "    agluon_img_train_data = []\n",
    "    for i in range(len(img_data.columns)):\n",
    "        from itertools import zip_longest\n",
    "        curr_img_feature = pd.DataFrame.from_records(zip_longest(\n",
    "            *img_data.iloc[:, i].parallel_apply(lambda x: x[0].asnumpy()).values)).transpose()\n",
    "        agluon_img_train_data.append(task.Dataset(curr_img_feature))\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train on each existing modality\n",
    "if has_text:\n",
    "    predictor_text = task.load(model_path+'text/')\n",
    "    print('done loading text model')\n",
    "if has_num:\n",
    "    predictor_num = task.load(model_path+'num/')\n",
    "    print('done loading num model')\n",
    "if has_cat:\n",
    "    predictor_cat = task.load(model_path+'cat/')\n",
    "    print('done loading cat model')\n",
    "if has_img:\n",
    "    predictor_img = []\n",
    "    for i in range(len(agluon_img_train_data)):\n",
    "        task.load(model_path+'img/'+img_data.columns[i])\n",
    "    print('done loading img model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done generating num unimodal preds\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Required columns are missing from the provided dataset. Missing columns: ['list_price_currency_cat_GBP']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-472d90dcaa9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done generating num unimodal preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_cat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpreds_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magluon_cat_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done generating cat unimodal preds'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhas_img\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/task/tabular_prediction/predictor.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, dataset, model, as_pandas, as_multiclass)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_pandas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_multiclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# TODO: Add pred_proba_cache functionality as in predict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_multiclass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0my_pred_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/utils/tabular/ml/learner/abstract_learner.py\u001b[0m in \u001b[0;36mtransform_features\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_generator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_generators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/utils/tabular/utils/decorators.py\u001b[0m in \u001b[0;36minner1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbegin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# storing time after function execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/autogluon/utils/tabular/features/abstract_feature_generator.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mmissing_cols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_cols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Required columns are missing from the provided dataset. Missing columns: {missing_cols}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures_init_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Required columns are missing from the provided dataset. Missing columns: ['list_price_currency_cat_GBP']"
     ]
    }
   ],
   "source": [
    "if has_text:\n",
    "    preds_text = predictor_text.predict_proba(agluon_text_train_data)\n",
    "    print('done generating text unimodal preds')\n",
    "if has_num:\n",
    "    preds_num = predictor_num.predict_proba(agluon_num_train_data)\n",
    "    print('done generating num unimodal preds')\n",
    "if has_cat:\n",
    "    preds_cat = predictor_cat.predict_proba(agluon_cat_train_data)\n",
    "    print('done generating cat unimodal preds')\n",
    "if has_img:\n",
    "    preds_img = []\n",
    "    for i in range(len(predictor_img)):\n",
    "        preds_img.append(predictor_img[i].predict_proba(agluon_img_train_data[i]))\n",
    "    print('done generating img unimodal preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phase 2 - wholistic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "wholistic_test = pd.DataFrame()\n",
    "if has_text:\n",
    "    wholistic_test = pd.concat([wholistic_test, pd.DataFrame(preds_text)], axis=1)\n",
    "if has_num:\n",
    "    wholistic_test = pd.concat([wholistic_test, pd.DataFrame(preds_num)], axis=1)\n",
    "if has_cat:\n",
    "    wholistic_test = pd.concat([wholistic_test, pd.DataFrame(preds_cat)], axis=1)\n",
    "if has_img:\n",
    "    wholistic_test = pd.concat([wholistic_test, pd.DataFrame(preds_img)], axis=1)\n",
    "wholistic_input_size = wholistic_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(\n",
    "        int(wholistic_input_size*float(2/3))+numcats,\n",
    "        input_shape=(wholistic_input_size,),\n",
    "        activation='relu')\n",
    "    )\n",
    "    model.add(layers.Dense(int(wholistic_input_size*float(1/3))+numcats, activation='relu'))\n",
    "    model.add(layers.Dense(numcats, activation='sigmoid'))\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "        optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./opt/ml/model/wholistic/wholistic_model')\n",
    "print('model loaded. predicting...')\n",
    "preds = model.predict(wholistic_test.values)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getmaplabs(pred):\n",
    "    return pred.tolist().index(max(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unmap(mappedlab):\n",
    "    return invcatmap[mappedlab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predlabs = pd.DataFrame(preds).parallel_apply(getmaplabs, axis=1)\n",
    "predlabs = predlabs.apply(unmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_dataset[[id_column]]\n",
    "submission[label] = predlabs\n",
    "submission.to_csv('./Submissions/ptc-submission_container-alg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
